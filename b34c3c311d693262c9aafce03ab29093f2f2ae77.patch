From b34c3c311d693262c9aafce03ab29093f2f2ae77 Mon Sep 17 00:00:00 2001
From: kosmichak <kosmitchak@gmail.com>
Date: Sun, 24 Sep 2017 15:19:56 +0200
Subject: [PATCH] Hotplug: update thunderplug

---
 arch/arm64/hotplug/thunderplug.c | 324 +++++++++++++++++++++++++++++----------
 kernel/sched/fair.c              |   4 +
 2 files changed, 247 insertions(+), 81 deletions(-)

diff --git a/arch/arm64/hotplug/thunderplug.c b/arch/arm64/hotplug/thunderplug.c
index 51b08ef34..af97fb991 100644
--- a/arch/arm64/hotplug/thunderplug.c
+++ b/arch/arm64/hotplug/thunderplug.c
@@ -9,7 +9,8 @@
  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
  * GNU General Public License for more details.
  *
- * A simple hotplugging driver optimized for Octa Core CPUs
+ * A simple hotplugging driver.
+ * Compatible from dual core CPUs to Octa Core CPUs
  */
 
 #include <linux/module.h>
@@ -21,33 +22,50 @@
 #include <linux/cpu.h>
 #include <linux/lcd_notify.h>
 #include <linux/cpufreq.h>
+#include "thunderplug.h"
 
-static int suspend_cpu_num = 2, resume_cpu_num = 7;
-static int endurance_level = 0;
-static int device_cpus = 8;
-static int core_limit = 8;
+#define DEBUG                        0
 
-static bool isSuspended = false;
+#define THUNDERPLUG                  "thunderplug"
 
-struct notifier_block lcd_worker;
+#define DRIVER_VERSION                5
+#define DRIVER_SUBVER                 0
 
-#define DEBUG 0
+#define DEFAULT_CPU_LOAD_THRESHOLD   (65)
+#define MIN_CPU_LOAD_THRESHOLD       (10)
 
-#define THUNDERPLUG "thunderplug"
+#define HOTPLUG_ENABLED              (0)
+#define DEFAULT_HOTPLUG_STYLE         HOTPLUG_SCHED
+#define DEFAULT_SCHED_MODE            BALANCED
 
-#define DRIVER_VERSION  2
-#define DRIVER_SUBVER 5
+#define DEF_SAMPLING_MS	             (500)
+#define MIN_SAMLING_MS               (50)
+#define MIN_CPU_UP_TIME              (750)
+#define TOUCH_BOOST_ENABLED          (0)
 
-#define CPU_LOAD_THRESHOLD        (65)
+static bool isSuspended = false;
 
-#define DEF_SAMPLING_MS			(500)
+struct notifier_block lcd_worker;
+
+static int suspend_cpu_num = 2, resume_cpu_num = (NR_CPUS -1);
+static int endurance_level = 0;
+static int core_limit = NR_CPUS;
+
+static int now[8], last_time[8];
 
 static int sampling_time = DEF_SAMPLING_MS;
-static int load_threshold = CPU_LOAD_THRESHOLD;
+static int load_threshold = DEFAULT_CPU_LOAD_THRESHOLD;
+static int stop_boost = 0;
 
-static int tplug_hp_enabled = 1;
+struct cpufreq_policy old_policy[NR_CPUS];
 
-static int touch_boost_enabled = 0;
+#ifdef CONFIG_SCHED_HMP
+static int tplug_hp_style = DEFAULT_HOTPLUG_STYLE;
+#else
+static int tplug_hp_enabled = HOTPLUG_ENABLED;
+#endif
+static int tplug_sched_mode = DEFAULT_SCHED_MODE;
+static int touch_boost_enabled = TOUCH_BOOST_ENABLED;
 
 static struct workqueue_struct *tplug_wq;
 static struct delayed_work tplug_work;
@@ -58,7 +76,7 @@ static struct delayed_work tplug_boost;
 static struct workqueue_struct *tplug_resume_wq;
 static struct delayed_work tplug_resume_work;
 
-static unsigned int last_load[8] = {0, 0, 0, 0, 0, 0, 0, 0};
+static unsigned int last_load[8] = { 0 };
 
 struct cpu_load_data {
 	u64 prev_cpu_idle;
@@ -72,26 +90,31 @@ struct cpu_load_data {
 
 static DEFINE_PER_CPU(struct cpu_load_data, cpuload);
 
+
+/* Two Endurance Levels for Octa Cores,
+ * Two for Quad Cores and
+ * One for Dual
+ */
 static inline void offline_cpus(void)
 {
 	unsigned int cpu;
 	switch(endurance_level) {
 		case 1:
-			if(suspend_cpu_num > 4)
-				suspend_cpu_num = 4;
+			if(suspend_cpu_num > NR_CPUS / 2 )
+				suspend_cpu_num = NR_CPUS / 2;
 		break;
 		case 2:
-			if(suspend_cpu_num > 2)
-				suspend_cpu_num = 2;
+			if( NR_CPUS >=4 && suspend_cpu_num > NR_CPUS / 4)
+				suspend_cpu_num = NR_CPUS / 4;
 		break;
 		default:
 		break;
 	}
-	for(cpu = 7; cpu > (suspend_cpu_num - 1); cpu--) {
+	for(cpu = NR_CPUS - 1; cpu > (suspend_cpu_num - 1); cpu--) {
 		if (cpu_online(cpu))
 			cpu_down(cpu);
 	}
-	pr_info("%s: %d cpus were offlined\n", THUNDERPLUG, (device_cpus - suspend_cpu_num));
+	pr_info("%s: %d cpus were offlined\n", THUNDERPLUG, (NR_CPUS - suspend_cpu_num));
 }
 
 static inline void cpus_online_all(void)
@@ -99,21 +122,23 @@ static inline void cpus_online_all(void)
 	unsigned int cpu;
 	switch(endurance_level) {
 	case 1:
-		if(resume_cpu_num > 3 || resume_cpu_num == 1)
-			resume_cpu_num = 3;
+		if(resume_cpu_num > (NR_CPUS / 2) - 1 || resume_cpu_num == 1)
+			resume_cpu_num = ((NR_CPUS / 2) - 1);
 	break;
 	case 2:
-		if(resume_cpu_num > 1)
-			resume_cpu_num = 1;
+		if( NR_CPUS >= 4 && resume_cpu_num > ((NR_CPUS / 4) - 1))
+			resume_cpu_num = ((NR_CPUS / 4) - 1);
 	break;
 	case 0:
-		if(resume_cpu_num < 7)
-			resume_cpu_num = 7;
+			resume_cpu_num = (NR_CPUS - 1);
 	break;
 	default:
 	break;
 	}
 
+	if(DEBUG)
+		   pr_info("%s: resume_cpu_num = %d\n",THUNDERPLUG, resume_cpu_num);
+
 	for (cpu = 1; cpu <= resume_cpu_num; cpu++) {
 		if (cpu_is_offline(cpu))
 			cpu_up(cpu);
@@ -124,18 +149,52 @@ static inline void cpus_online_all(void)
 
 static void __ref tplug_boost_work_fn(struct work_struct *work)
 {
-	int cpu;
-	for(cpu = 1; cpu < 4; cpu++) {
+	struct cpufreq_policy policy;
+	int cpu, ret;
+	for(cpu = 1; cpu < NR_CPUS; cpu++) {
+#ifdef CONFIG_SCHED_HMP
+    if(tplug_hp_style == 1)
+#else
+	if(tplug_hp_enabled == 1)
+#endif
 		if(cpu_is_offline(cpu))
 			cpu_up(cpu);
+		ret = cpufreq_get_policy(&policy, cpu);
+		if (ret)
+			continue;
+		old_policy[cpu] = policy;
+		policy.min = policy.max;
+		cpufreq_update_policy(cpu);
 	}
+	if(stop_boost == 0)
+	queue_delayed_work_on(0, tplug_boost_wq, &tplug_boost,
+			msecs_to_jiffies(10));
 }
 
 static void tplug_input_event(struct input_handle *handle, unsigned int type,
 		unsigned int code, int value)
 {
-
-	if ((type == EV_KEY) && (code == BTN_TOUCH) && (value == 1) && touch_boost_enabled == 1)
+	if (type == EV_KEY && code == BTN_TOUCH) {
+		if(DEBUG)
+			pr_info("%s : type = %d, code = %d, value = %d\n", THUNDERPLUG, type, code, value);
+		if(value == 0) {
+			stop_boost = 1;
+			if(DEBUG)
+				pr_info("%s: stopping boost\n", THUNDERPLUG);
+		}
+		else {
+			stop_boost = 0;
+			if(DEBUG)
+				pr_info("%s: starting boost\n", THUNDERPLUG);
+		}
+	}
+#ifdef CONFIG_SCHED_HMP
+    if ((type == EV_KEY) && (code == BTN_TOUCH) && (value == 1)
+		&& touch_boost_enabled == 1)
+#else
+	if ((type == EV_KEY) && (code == BTN_TOUCH) && (value == 1)
+		&& touch_boost_enabled == 1)
+#endif
 	{
 		if(DEBUG)
 			pr_info("%s : touch boost\n", THUNDERPLUG);
@@ -203,7 +262,7 @@ static ssize_t thunderplug_suspend_cpus_store(struct kobject *kobj, struct kobj_
 {
 	int val;
 	sscanf(buf, "%d", &val);
-	if(val < 1 || val > 8)
+	if(val < 1 || val > NR_CPUS)
 		pr_info("%s: suspend cpus off-limits\n", THUNDERPLUG);
 	else
 		suspend_cpu_num = val;
@@ -220,11 +279,13 @@ static ssize_t __ref thunderplug_endurance_store(struct kobject *kobj, struct ko
 {
 	int val;
 	sscanf(buf, "%d", &val);
+	if(tplug_hp_style == 1) {
 	switch(val) {
 	case 0:
 	case 1:
 	case 2:
-		if(endurance_level!=val) {
+		if(endurance_level!=val &&
+		   !(endurance_level > 1 && NR_CPUS < 4)) {
 		endurance_level = val;
 		offline_cpus();
 		cpus_online_all();
@@ -234,6 +295,9 @@ static ssize_t __ref thunderplug_endurance_store(struct kobject *kobj, struct ko
 		pr_info("%s: invalid endurance level\n", THUNDERPLUG);
 	break;
 	}
+	}
+	else
+	   pr_info("%s: per-core hotplug style is disabled, ignoring endurance mode values\n", THUNDERPLUG);
 
 	return count;
 }
@@ -247,40 +311,12 @@ static ssize_t __ref thunderplug_sampling_store(struct kobject *kobj, struct kob
 {
 	int val;
 	sscanf(buf, "%d", &val);
-	if(val > 50)
+	if(val > MIN_SAMLING_MS)
 		sampling_time = val;
 
 	return count;
 }
 
-static ssize_t thunderplug_hp_enabled_show(struct kobject *kobj, struct kobj_attribute *attr, char *buf)
-{
-    return sprintf(buf, "%d", tplug_hp_enabled);
-}
-
-static ssize_t __ref thunderplug_hp_enabled_store(struct kobject *kobj, struct kobj_attribute *attr, const char *buf, size_t count)
-{
-	int val;
-	sscanf(buf, "%d", &val);
-	int last_val = tplug_hp_enabled;
-	switch(val)
-	{
-		case 0:
-		case 1:
-			tplug_hp_enabled = val;
-		break;
-		default:
-			pr_info("%s : invalid choice\n", THUNDERPLUG);
-		break;
-	}
-
-	if(tplug_hp_enabled == 1 && tplug_hp_enabled != last_val)
-		queue_delayed_work_on(0, tplug_wq, &tplug_work,
-							msecs_to_jiffies(sampling_time));
-
-	return count;
-}
-
 static ssize_t thunderplug_tb_enabled_show(struct kobject *kobj, struct kobj_attribute *attr, char *buf)
 {
     return sprintf(buf, "%d", touch_boost_enabled);
@@ -374,16 +410,16 @@ static void __cpuinit tplug_work_fn(struct work_struct *work)
 	switch(endurance_level)
 	{
 	case 0:
-		core_limit = 8;
+		core_limit = NR_CPUS;
 	break;
 	case 1:
-		core_limit = 4;
+		core_limit = NR_CPUS / 2;
 	break;
 	case 2:
-		core_limit = 2;
+		core_limit = NR_CPUS / 4;
 	break;
 	default:
-		core_limit = 8;
+		core_limit = NR_CPUS;
 	break;
 	}
 
@@ -404,19 +440,28 @@ static void __cpuinit tplug_work_fn(struct work_struct *work)
 	{
 	if(DEBUG)
 		pr_info("%s : bringing back cpu%d\n", THUNDERPLUG,i);
-		if(!((i+1) > 7))
+		if(!((i+1) > 7)) {
+			last_time[i+1] = ktime_to_ms(ktime_get());
 			cpu_up(i+1);
+		}
 	}
 	else if(cpu_online(i) && avg_load[i] < load_threshold && cpu_online(i+1))
 	{
-	if(DEBUG)
-		pr_info("%s : offlining cpu%d\n", THUNDERPLUG,i);
-		if(!(i+1)==0)
-			cpu_down(i+1);
-	}
+		if(DEBUG)
+			pr_info("%s : offlining cpu%d\n", THUNDERPLUG,i);
+			if(!(i+1)==0) {
+				now[i+1] = ktime_to_ms(ktime_get());
+				if((now[i+1] - last_time[i+1]) > MIN_CPU_UP_TIME)
+					cpu_down(i+1);
+			}
+		}
 	}
 
+#ifdef CONFIG_SCHED_HMP
+    if(tplug_hp_style == 1 && !isSuspended)
+#else
 	if(tplug_hp_enabled != 0 && !isSuspended)
+#endif
 		queue_delayed_work_on(0, tplug_wq, &tplug_work,
 			msecs_to_jiffies(sampling_time));
 	else {
@@ -434,7 +479,11 @@ static int lcd_notifier_callback(struct notifier_block *nb,
        switch (event) {
        case LCD_EVENT_ON_START:
 			isSuspended = false;
+#ifdef CONFIG_SCHED_HMP
+			if(tplug_hp_style==1)
+#else
 			if(tplug_hp_enabled)
+#endif
 				queue_delayed_work_on(0, tplug_wq, &tplug_work,
 								msecs_to_jiffies(sampling_time));
 			else
@@ -457,6 +506,120 @@ static int lcd_notifier_callback(struct notifier_block *nb,
        return 0;
 }
 
+/* Thunderplug load balancer */
+#ifdef CONFIG_SCHED_HMP
+
+static void set_sched_profile(int mode) {
+    switch(mode) {
+	   case 1:
+	       /* Balanced */
+	       sched_set_boost(DISABLED);
+	   break;
+	   case 2:
+	       /* Turbo */
+	       sched_set_boost(ENABLED);
+	   break;
+	   default:
+	       pr_info("%s: Invalid mode\n", THUNDERPLUG);
+	   break;
+	}
+}
+
+static ssize_t thunderplug_sched_mode_show(struct kobject *kobj, struct kobj_attribute *attr, char *buf)
+{
+    return sprintf(buf, "%d", tplug_sched_mode);
+}
+
+static ssize_t __ref thunderplug_sched_mode_store(struct kobject *kobj, struct kobj_attribute *attr, const char *buf, size_t count)
+{
+	int val;
+	sscanf(buf, "%d", &val);
+	set_sched_profile(val);
+	tplug_sched_mode = val;
+	return count;
+}
+
+static ssize_t thunderplug_hp_style_show(struct kobject *kobj, struct kobj_attribute *attr, char *buf)
+{
+    return sprintf(buf, "%d", tplug_hp_style);
+}
+
+static ssize_t __ref thunderplug_hp_style_store(struct kobject *kobj, struct kobj_attribute *attr, const char *buf, size_t count)
+{
+	int val, last_val;
+	sscanf(buf, "%d", &val);
+	last_val = tplug_hp_style;
+	switch(val)
+	{
+		case HOTPLUG_PERCORE:
+		case HOTPLUG_SCHED:
+			   tplug_hp_style = val;
+		break;
+		default:
+			pr_info("%s : invalid choice\n", THUNDERPLUG);
+		break;
+	}
+
+	if(tplug_hp_style == HOTPLUG_PERCORE && tplug_hp_style != last_val) {
+	    pr_info("%s: Switching to Per-core hotplug model\n", THUNDERPLUG);
+	    sched_set_boost(DISABLED);
+		queue_delayed_work_on(0, tplug_wq, &tplug_work,
+							msecs_to_jiffies(sampling_time));
+	}
+	else if(tplug_hp_style==2) {
+	    pr_info("%s: Switching to sched based hotplug model\n", THUNDERPLUG);
+	    set_sched_profile(tplug_sched_mode);
+	}
+
+	return count;
+}
+
+static struct kobj_attribute thunderplug_hp_style_attribute =
+       __ATTR(hotplug_style,
+               0666,
+               thunderplug_hp_style_show, thunderplug_hp_style_store);
+
+static struct kobj_attribute thunderplug_mode_attribute =
+       __ATTR(sched_mode,
+               0666,
+               thunderplug_sched_mode_show, thunderplug_sched_mode_store);
+
+#else
+static ssize_t thunderplug_hp_enabled_show(struct kobject *kobj, struct kobj_attribute *attr, char *buf)
+{
+    return sprintf(buf, "%d", tplug_hp_enabled);
+}
+
+static ssize_t __ref thunderplug_hp_enabled_store(struct kobject *kobj, struct kobj_attribute *attr, const char *buf, size_t count)
+{
+	int val;
+	sscanf(buf, "%d", &val);
+	int last_val = tplug_hp_enabled;
+	switch(val)
+	{
+		case 0:
+		case 1:
+			tplug_hp_enabled = val;
+		break;
+		default:
+			pr_info("%s : invalid choice\n", THUNDERPLUG);
+		break;
+	}
+
+	if(tplug_hp_enabled == 1 && tplug_hp_enabled != last_val)
+		queue_delayed_work_on(0, tplug_wq, &tplug_work,
+							msecs_to_jiffies(sampling_time));
+
+	return count;
+}
+
+static struct kobj_attribute thunderplug_hp_enabled_attribute =
+       __ATTR(hotplug_enabled,
+               0666,
+               thunderplug_hp_enabled_show, thunderplug_hp_enabled_store);
+
+#endif
+
 static ssize_t thunderplug_ver_show(struct kobject *kobj, struct kobj_attribute *attr, char *buf)
 {
        return sprintf(buf, "ThunderPlug %u.%u", DRIVER_VERSION, DRIVER_SUBVER);
@@ -487,11 +650,6 @@ static struct kobj_attribute thunderplug_load_attribute =
                0666,
                thunderplug_load_show, thunderplug_load_store);
 
-static struct kobj_attribute thunderplug_hp_enabled_attribute =
-       __ATTR(hotplug_enabled,
-               0666,
-               thunderplug_hp_enabled_show, thunderplug_hp_enabled_store);
-
 static struct kobj_attribute thunderplug_tb_enabled_attribute =
        __ATTR(touch_boost,
                0666,
@@ -504,7 +662,12 @@ static struct attribute *thunderplug_attrs[] =
         &thunderplug_endurance_attribute.attr,
         &thunderplug_sampling_attribute.attr,
         &thunderplug_load_attribute.attr,
+#ifdef CONFIG_SCHED_HMP
+        &thunderplug_mode_attribute.attr,
+        &thunderplug_hp_style_attribute.attr,
+#else
         &thunderplug_hp_enabled_attribute.attr,
+#endif
         &thunderplug_tb_enabled_attribute.attr,
         NULL,
     };
@@ -570,6 +733,5 @@ static int __init thunderplug_init(void)
 
 MODULE_LICENSE("GPL and additional rights");
 MODULE_AUTHOR("Varun Chitre <varun.chitre15@gmail.com>");
-MODULE_DESCRIPTION("Hotplug driver for OctaCore CPU");
+MODULE_DESCRIPTION("Hotplug driver for ARM SoCs");
 late_initcall(thunderplug_init);
-
diff --git a/kernel/sched/fair.c b/kernel/sched/fair.c
index 97ac2228f..3ffea0898 100755
--- a/kernel/sched/fair.c
+++ b/kernel/sched/fair.c
@@ -49,6 +49,10 @@
 #include <linux/hisi/pm/pwrctrl_multi_memcfg.h>
 #endif
 
+#ifdef CONFIG_THUNDERPLUG_CONTROL
+EXPORT_SYMBOL_GPL(sched_set_boost);
+#endif
+
 #if defined(CONFIG_ARCH_HI3XXX)||defined(CONFIG_ARCH_HI6XXX)
 /* Add apportunity to config how to placement the task
  * when task fork.
